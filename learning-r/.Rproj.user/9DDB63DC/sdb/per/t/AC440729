{
    "contents" : "# Getting Data\n# Chapter Goals:\n## Access datasets provided with R packages\n## Import data from text files\n## Import data from binary files\n## download data from websites\n## import data from a database\n\n# See all datasets available in loaded packages via data:\ndata()\n\n# see all datasets in all installed packages:\ndata(package = .packages(TRUE))\n\n# load a particular dataset\ndata(\"kidney\", package = \"survival\")\n# see the first few rows\nhead(kidney)\n\n#### Reading text files\n# read.table used for CSV and TSV\ninstall.packages(\"learningr\")\nlibrary(learningr)\ndata(package = \"learningr\")\n\ndeer_file <- system.file(\n  \"extdata\",\n  \"RedDeerEndocranialVolume.dlm\",\n  package = \"learningr\"\n  )\n\ndeer_data <- read.table(deer_file, header = TRUE,\n                        fill = TRUE) # change the missings to NAs\nstr(deer_data, vec.len = 1) # vec.len alters the amount of output\nstr(deer_data)\nhead(deer_data)\n\n# Column classes have been determined, row and column names have been assigned\n# variable names are forced to be valid, and row names are added if they haven't been provided\n\n# sep - most important argument, which determines the separator\n# nrow - how many lines to read\n# skip - how many lines to skip at the start\n\n# wrappers:\n## read.csv sets the default separator to a comma, assumes the data has a header row\n## read.csv2 is for european data\n## read.delim - tab-delimited\n\n### Crab-data\n# need the skip and nrow:\n\ncrab_file <- system.file(\n  \"extdata\",\n  \"crabtag.csv\",\n  package = \"learningr\")\n(crab_id_block <- read.csv(\n  crab_file,\n  header = FALSE,\n  skip = 3,\n  nrow = 2\n  ))\n(crab_tag_notebook <- read.csv(\n  crab_file,\n  header = FALSE,\n  skip = 8,\n  nrow = 5\n  ))\n(crab_lifetime_notebook <- read.csv(\n  crab_file,\n  header = FALSE,\n  skip = 15,\n  nrow = 3\n  ))\n\n# use colbycol to read part of a CSV into R\n# use sqldf to read part of a csv\n\n# scan can be used with malformed badly formatted data files\n\n# na.strings for other languages\n# for SQL exports, use na.strings = \"NULL\"\n# for SAS or Stata, use na.strings = \".\"\n# for Excel, use na.strings = c(\"\", \"#N/A\", \"#DIV/0!\", \"#NUM!\")\n\n## Writing files\n# write.table and write.csv\n# take a data frame and a file path\n\n# Unstructured text files\n# readLines - filepath or connection, max # of lines to read\ntext_file <- system.file(\n  \"extdata\",\n  \"Shakespeare.s.The.Tempest..from.Project.Gutenberg.pg2235.txt\",\n  package = \"learningr\"\n  )\nthe_tempest <- readLines(text_file)\nthe_tempest[1926:1927]\n\n# writeLines is the reverse\nwriteLines(\n  rev(text_file), # rev reverses a vector\n  \"Shakespeare's The Tempest, backwards.txt\"\n  )\n\n## XML and HTML\n### RSS, Simple Object Access Protocol, XHTML\n\ninstall.packages(\"XML\")\n# when you import XML, you want to store things with internal nodes, not R nodes\n# internal nodes allows you to use XPath\n# R nodes allow you to use str and head\n\nlibrary(XML)\nxml_file <- system.file(\"extdata\", \"options.xml\", package = \"learningr\")\nr_options <- xmlParse(xml_file)\n\n# XPath interrogates XMl - let's you find nodes that correspond to a filter\n# // - look anywhere in a document\n# variable - looking for a node named this\n# where [] the name attribute contains the string warn:\nxpathSApply(r_options, \"//variable[contains(@name, 'warn')]\")\n\n# you can use this with HTML - htmlParse\n\n# XML is also useful for serializing/saving objects in a format\n# that can be read by most other pieces of software\n# serialization is available from makexml in Runiversal\n\ninstall.packages(\"Runiversal\")\nlibrary(Runiversal)\nops <- as.list(options())\ncat(makexml(ops), file = \"options.xml\")\n\n##### JSON and YAML Files\n# XML problems - very verbose, need to explicitly specify the type of data\n# (string vs number) which makes it more verbose\n# YAML and JSON are intended to solve these\n\n# rjson works well\n# RJSONIO works with malformed data better\n## both functions have identically-named functions\n\ninstall.packages(\"RJSONIO\")\nlibrary(RJSONIO)\n\njamaicanCityFile <- system.file(\n  \"extdata\",\n  \"Jamaican.Cities.json\",\n  package = \"learningr\")\n\n(jamaicanCities <- fromJSON(jamaicanCityFile))\n# coordinates are currently listed as a vector\n# you can turn this off with simplify = FALSE\n(jamaicanCities <- fromJSON(jamaicanCityFile, simplify = FALSE))\n\n# infinite and NaNs\n# RJSONIO maps NaN and NA to null\n# RJSONIO preserves positive and negative infinity\n\nspecialNumbers <- c(NaN, NA, Inf, -Inf)\ntoJSON(specialNumbers)\n\n# If you have a lot of NA, NaN, or Infinite values, use YAML\ninstall.packages(\"yaml\")\nlibrary(yaml)\n\n# yaml.load accepts a YAML string\n# yaml.load_file accepts a filepath string for YAML\n\nyaml.load_file(jamaicanCityFile)\n\n# as.yaml is the reverse - converts R files to YAML strings\n\n\n### Reading Binary files\n# Excel files is the classic example:\n# use xlsx\ninstall.packages(\"xlsx\")\n# function xlsx2 uses Java, which is native\n# Use colClasses to set data types in the data frame on import\nlibrary(xlsx)\n\nbikeFile <- system.file(\n  \"extdata\",\n  \"Alpe.d.Huez.xls\",\n  package = \"learningr\"\n  )\nbikeData <- read.xlsx2(\n  bikeFile,\n  sheetIndex = 1,\n  startRow = 2,\n  endRow = 38,\n  colIndex = 2:8,\n  colClasses = c(\n    \"character\", \"numeric\", \"character\", \"integer\",\n    \"character\", \"character\", \"character\"\n    )\n  )\nhead(bikeData)\n\n# write.xlsx2 allows you to write excel files\n\n##### Reading SAS, Stata, SPSS, and MATLAB\n# use foreign\nlibrary(foreign)\n##### Reading other file types\n# Hierarchical Data Format v5 - HDF5 via h5r\n# Network Common Data Format - NetCDF via ncdf\n# ESRI ArcGIS spatial files - via maptools and shapefiles\n# Older ArcInfo files - via RArcInfo\n# Raster pictures: jpeg, png, tiff, rtiff, readbitmap\n# Genomics data using Bioconductor packages\n# Microarray data in GenePix GPR - via RPPanalyzer\n\n##### Web data\n# APIs -\n## World Bank - World Development Indicators data\ninstall.packages(\"WDI\")\nlibrary(WDI)\n#list all available datasets\nwdiDatasets <- WDIsearch()\nhead(wdiDatasets)\n\n# get one of the datasets\nwdiTradeInServices <- WDI(indicator = \"BG.GSR.NFSV.GD.ZS\")\nstr(wdiTradeInServices)\n\n# stock tickers: quantmod\ninstall.packages(\"quantmod\")\nlibrary(quantmod)\n# If you are using a version before 0.5.0 then set this option\n# or pass auto-assign = FALSE to getSymbols\noptions(getSymbols.auto.assign = FALSE)\nmicrosoft <- getSymbols(\"MSFT\")\nhead(microsoft)\nnrow(microsoft)\nlength(microsoft)\n\n# twitter - twitteR\n\n##### Scraping Web Pages\n# read.table is Internet-enabled by default\nsalaryURL <- \"http://www.justinmrao.com/salary_data.csv\"\nsalaryData <- read.csv(salaryURL)\nstr(salaryData)\n\n# You can also download files:\nlocalCopy <- \"my local copy.csv\"\ndownload.file(salaryURL, localCopy)\nsalaryData <- read.csv(localCopy)\n\n# RCurl is used for getting HTML and XML off the web\n# getURL retrieves the page as a character string\ninstall.packages(\"RCurl\")\nlibrary(RCurl)\ntimeURL <- \"http://tycho.usno.navy.mil/cgi-bin/timer.pl\"\ntimePage <- getURL(timeURL)\ncat(timePage)\n\n# now you need to parse the page:\ninstall.packages(\"XML\")\nlibrary(XML)\ntimeDoc <- htmlParse(timePage)\npre <- xpathSApply(timeDoc, \"//pre\")[[1]]\n# splitting on \\n retrieves each time line\nvalues <- strsplit(xmlValue(pre), \"\\n\")[[1]][-1]\n# splitting on \\t (tabs) retrieves time/time zone pairs\nstrsplit(values, \"\\t+\")\n\n# another option is httr, which makes some things go easier:\ninstall.packages(\"httr\")\nlibrary(httr)\ntimePage <- GET(timeURL)\ntimeDoc <- content(page, useInternalNodes = TRUE)\n\n##### Accessing Databases\n# DBI provides a unified syntax for:\n# SQLite, MySQL/MariaDB, PostgreSQL, Oracle, JDBC\n\ninstall.packages(\"DBI\")\nlibrary(DBI)\ninstall.packages(\"RSQLite\")\nlibrary(RSQLite)\n\n## for SQLite\ndriver <- dbDriver(\"SQLite\")\ndbFile <- system.file(\"extdata\", \"crabtag.sqlite\", package = \"learningr\")\nconn <- dbConnect(driver, dbFile)\n\n# for MySQL\n# Note, this doesn't work\ndriver <- dbDriver(\"MySQL\")\ndbFile <- \"path/to/MySQL/database\"\nconn <- dbConnect(driver,dbFile)\n\n# Other libraries:\ninstall.packages(\"PostgreSQL\")\ninstall.packages(\"ROracle\")\ninstall.packages(\"RJDBC\")\n\n# write queries\nquery <- \"SELECT * FROM IdBlock\"\n(idBlock <- dbGetQuery(conn, query))\n\n# when you're done, you need to disconnect and unload the driver\ndbDisconnect(conn)\ndbUnloadDriver(driver)\n\nrm(\"conn\")\nrm(\"driver\")\n\nlibrary(DBI)\nlibrary(RSQLite)\n## Use a function to open connections, and add on.exit in the function to close and disconnect\nqueryCrabTagDB <- function(query)\n{\n  driver <- dbDriver(\"SQLite\")\n  dbFile <- system.file(\"extdata\", \"crabtag.sqlite\", package = \"learningr\")\n  conn <- dbConnect(driver, dbFile)\n  on.exit(\n    {\n      # this code block runs at the end of the function\n      # even if an error is thrown\n      dbDisconnect(conn)\n      dbUnloadDriver(driver)\n    }\n    )\n  dbGetQuery(conn, query)\n}\n\nqueryCrabTagDB(\"SELECT * FROM IdBlock\")\n\n# DBI provides some useful functions:\n## dbReadTable reads a table from the connected database - SELECT *\n## dbListTables(conn) lists the table names\n\ndbReadTable(conn, \"idblock\")\n\n\n### YOU can also do all of this via ODBC\n# RODBC is the package\n# you need to have an ODBC data source set up on your machine\n# then:\n# odbcConnect to connect to the db\n# sqlQuery to run a query\n# odbcClose to clean up afterward\n\n# Mongo: \ninstall.packages(\"RMongo\")\ninstall.packages(\"rmongodb\")\n\n####### Exercises:\n# 12-1 - import hafu.csv into a data frame\n\nmangaFile <- system.file(\"extdata\", \"hafu.csv\", package = \"learningr\")\nmangaDF <- read.csv(mangaFile)\n\n# 12-2 - import the first sheet of the excel file\nlibrary(\"xlsx\")\ninfectionFile <- system.file(\"extdata\",\n                             \"multi.drug.resistant.gonorrhoea.infection.xls\",\n                             package = \"learningr\")\ninfectionData <- read.xlsx2(infectionFile,\n                            sheetIndex = 1,\n                            startRow = 1,\n                            endRow = 101,\n                            colIndex = 1:4,\n                            colClasses = c(\"numeric\",\"character\", \"character\", \"numeric\"))\nstr(infectionData)\n\n# 12-3 import the Daylog table into a data frame\ndriver <- dbDriver(\"SQLite\")\ndbFile <- system.file(\"extdata\", \"crabtag.sqlite\", package = \"learningr\")\nconn <- dbConnect(driver, dbFile)\ntempTable <- dbReadTable(conn, \"Daylog\")\ndbDisconnect(conn)\ndbUnloadDriver(driver)\n",
    "created" : 1430319499742.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "909126844",
    "id" : "AC440729",
    "lastKnownWriteTime" : 1429741502,
    "path" : "~/Documents/github/core-r/learning-r/C_12.R",
    "project_path" : "C_12.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}